<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Towards Robust and Controllable Text-to-Motion<br>via Masked Autoregressive Diffusion</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MoMADiff</h1>
            <h2 class="subtitle is-3 publication-subtitle" ,="" style="margin-bottom: 20px;">
              Towards Robust and Controllable Text-to-Motion<br>via Masked Autoregressive Diffusion
            </h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://zzysteve.github.io/" target="_blank">Zongye Zhang</a>,</span>
                <span class="author-block">
                  <a href="https://orcid.org/0009-0006-3813-0427" target="_blank">Bohan Kong</a>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=HsLdRZYAAAAJ" target="_blank">Qingjie Liu<sup>*</sup></a>,
                  </span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=0ez7lA0AAAAJ" target="_blank">Yunhong Wang</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">State Key Laboratory of Virtual Reality Technology and Systems, Beihang University<br>
                      Hangzhou Innovation Institute, Beihang University
                      <br>ACM MM 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.11013.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/zzysteve/MoMADiff" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.11013" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls height="100%">
        <!-- Your video here -->
        <source src="static/videos/momadiff/banner.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating 3D human motion from text descriptions remains challenging due to the diverse and complex nature of human motion. While existing methods excel within the training distribution, they often struggle with out-of-distribution motions, limiting their applicability in real-world scenarios. Existing VQVAE-based methods often fail to represent novel motions faithfully using discrete tokens, which hampers their ability to generalize beyond seen data. Meanwhile, diffusion-based methods operating on continuous representations often lack fine-grained control over individual frames. To address these challenges, we propose a robust motion generation framework MoMADiff, which combines masked modeling with diffusion processes to generate motion using frame-level continuous representations. Our model supports flexible user-provided keyframe specification, enabling precise control over both spatial and temporal aspects of motion synthesis. MoMADiff demonstrates strong generalization capability on novel text-to-motion datasets with sparse keyframes as motion prompts. Extensive experiments on two held-out datasets and two standard benchmarks show that our method consistently outperforms state-of-the-art models in motion quality, instruction fidelity, and keyframe adherence. The code is available at: https://github.com/zzysteve/MoMADiff.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Motivation section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Motivation</h2>
      <div class="columns is-centered">
        <div class="column is-two-thirds">
          <div class="columns is-centered">
            <div class="column is-10">
              
              <h3 class="subtitle has-text-centered" style="margin-bottom: 25px;">
                Existing methods struggle with out-of-distribution motions
              </h3>

              <div class="columns is-multiline is-centered">
                
                <div class="column is-full">
                  <video poster="" id="motivation-video1" autoplay controls muted loop height="100%">
                    <source src="static/videos/momadiff/motivation_poor_reconstruction.mp4" type="video/mp4">
                  </video>
                  <h3 class="subtitle has-text-centered" style="margin-top: 20px;">
                    <strong>Inaccurate motion reconstruction</strong>
                  </h3>
                </div> <div class="column is-full">
                  <video poster="" id="motivation-video2" autoplay controls muted loop height="100%">
                    <source src="static/videos/momadiff/motivation_poor_guidance.mp4" type="video/mp4">
                  </video>
                  <h3 class="subtitle has-text-centered" style="margin-top: 20px;">
                    <strong>Poor keyframe guidance</strong>
                  </h3>
                </div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End motivation section -->



<!-- Static image section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Overview</h2>
      <div class="columns is-centered">
        <div class="column is-two-thirds">
          <img src="static/images/momadiff/overview.jpg" alt="Overview of our method"/>
          <h2 class="subtitle has-text-centered" style="margin-top: 20px;">
            Our approach combines a <strong>Motion VAE</strong> for high-fidelity reconstruction with a <strong>masked autoregressive diffusion model</strong> for generation. This design enables realistic motion synthesis and allows for precise control via sparse keyframes.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End static image section -->

<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Qualitative Results</h2>
      <div class="columns is-centered">
        <div class="column is-three-quarters">
          <div id="videos-carousel" class="carousel results-carousel">
            <div class="item item-video1">
              <video poster="" id="video1" autoplay controls muted loop height="100%">
                <!-- Your video file here -->
                <source src="static/videos/momadiff/01_motion_reconstruction.mp4"
                type="video/mp4">
              </video>
            </div>
            <div class="item item-video2">
              <video poster="" id="video2" autoplay controls muted loop height="100%">
                <!-- Your video file here -->
                <source src="static/videos/momadiff/02_keyframe_guided_generation.mp4"
                type="video/mp4">
              </video>
            </div>
            <div class="item item-video3">
              <video poster="" id="video3" autoplay controls muted loop height="100%">
                <!-- Your video file here -->
                <source src="static/videos/momadiff/03_ours_applications.mp4"
                type="video/mp4">
              </video>
            </div>
            <div class="item item-video4">
              <video poster="" id="video4" autoplay controls muted loop height="100%">
                <!-- Your video file here -->
                <source src="static/videos/momadiff/04_ours_on_humanml3d.mp4"
                type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->

<!-- Static image section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Quantitative Results</h2>
      <div class="columns is-centered">
        <div class="column is-two-thirds">
          <img src="static/images/momadiff/standard_qual.jpg" alt="Qualitative results on two standard benchmarks."/>
          <h2 class="subtitle has-text-left" style="margin-top: 20px;">
            Qualitative results on two standard benchmarks. Our method outperforms existing state-of-the-art approaches on both HumanML3D and KIT-ML benchmarks in terms of motion quality and text-motion fidelity.
          </h2>
          <img src="static/images/momadiff/ood_motion_qual.jpg" alt="Quantitative comparison results." style="margin-top: 30px;"/>
          <h2 class="subtitle has-text-left" style="margin-top: 20px;">
            Our method demonstrates strong generalization capability on out-of-distribution motions with sparse keyframes as motion prompts, significantly outperforming existing methods.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End static image section -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{zhang2025towards,
  title={Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion},
  author={Zhang, Zongye and Kong, Bohan and Liu, Qingjie and Wang, Yunhong},
  journal={arXiv preprint arXiv:2505.11013},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
